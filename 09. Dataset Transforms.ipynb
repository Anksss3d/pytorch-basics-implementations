{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defimne Dataset Manager using Dataset Class from torch\n",
    "\n",
    "class WineDataset(Dataset):\n",
    "    #constructor\n",
    "    def __init__(self, transform=None):\n",
    "        xy = np.loadtxt('./Datasets/wine.csv', delimiter=\",\", dtype=np.float32, skiprows=1)\n",
    "        self.x = xy[:, 1:]\n",
    "        self.y = xy[:, [0]]\n",
    "        \n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    \n",
    "    \n",
    "    #method for indexing and retrieving objects with index\n",
    "    def __getitem__(self, index):\n",
    "        \n",
    "        sample = self.x[index], self.y[index]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample\n",
    "    \n",
    "    \n",
    "    #Method to find length of the dataset\n",
    "    def __len__(self):\n",
    "        return self.n_samples\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class toTensor:\n",
    "    def __call__(self, sample):\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "\n",
    "    \n",
    "class mulTransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        inputs, targets  = sample\n",
    "        inputs = self.factor * inputs\n",
    "        return inputs, targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Composed Transform\n",
    "composed = torchvision.transforms.Compose([toTensor(), mulTransform(0.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Dataset Object \n",
    "dataset = WineDataset(transform= composed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([7.1150e+00, 8.5500e-01, 1.2150e+00, 7.8000e+00, 6.3500e+01, 1.4000e+00,\n",
      "        1.5300e+00, 1.4000e-01, 1.1450e+00, 2.8200e+00, 5.2000e-01, 1.9600e+00,\n",
      "        5.3250e+02]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "#Check the dataset\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use of Dataloader\n",
    "dataloader = DataLoader(dataset=dataset, batch_size=2, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "178 45\n"
     ]
    }
   ],
   "source": [
    "epochs = 2\n",
    "total_samples = len(dataset)\n",
    "n_iterations = math.ceil(total_samples/4)\n",
    "print(total_samples, n_iterations)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, iteration: 2\n",
      "epoch: 0, iteration: 4\n",
      "epoch: 0, iteration: 6\n",
      "epoch: 0, iteration: 8\n",
      "epoch: 0, iteration: 10\n",
      "epoch: 0, iteration: 12\n",
      "epoch: 0, iteration: 14\n",
      "epoch: 0, iteration: 16\n",
      "epoch: 0, iteration: 18\n",
      "epoch: 0, iteration: 20\n",
      "epoch: 0, iteration: 22\n",
      "epoch: 0, iteration: 24\n",
      "epoch: 0, iteration: 26\n",
      "epoch: 0, iteration: 28\n",
      "epoch: 0, iteration: 30\n",
      "epoch: 0, iteration: 32\n",
      "epoch: 0, iteration: 34\n",
      "epoch: 0, iteration: 36\n",
      "epoch: 0, iteration: 38\n",
      "epoch: 0, iteration: 40\n",
      "epoch: 0, iteration: 42\n",
      "epoch: 0, iteration: 44\n",
      "epoch: 0, iteration: 46\n",
      "epoch: 0, iteration: 48\n",
      "epoch: 0, iteration: 50\n",
      "epoch: 0, iteration: 52\n",
      "epoch: 0, iteration: 54\n",
      "epoch: 0, iteration: 56\n",
      "epoch: 0, iteration: 58\n",
      "epoch: 0, iteration: 60\n",
      "epoch: 0, iteration: 62\n",
      "epoch: 0, iteration: 64\n",
      "epoch: 0, iteration: 66\n",
      "epoch: 0, iteration: 68\n",
      "epoch: 0, iteration: 70\n",
      "epoch: 0, iteration: 72\n",
      "epoch: 0, iteration: 74\n",
      "epoch: 0, iteration: 76\n",
      "epoch: 0, iteration: 78\n",
      "epoch: 0, iteration: 80\n",
      "epoch: 0, iteration: 82\n",
      "epoch: 0, iteration: 84\n",
      "epoch: 0, iteration: 86\n",
      "epoch: 0, iteration: 88\n",
      "epoch: 1, iteration: 2\n",
      "epoch: 1, iteration: 4\n",
      "epoch: 1, iteration: 6\n",
      "epoch: 1, iteration: 8\n",
      "epoch: 1, iteration: 10\n",
      "epoch: 1, iteration: 12\n",
      "epoch: 1, iteration: 14\n",
      "epoch: 1, iteration: 16\n",
      "epoch: 1, iteration: 18\n",
      "epoch: 1, iteration: 20\n",
      "epoch: 1, iteration: 22\n",
      "epoch: 1, iteration: 24\n",
      "epoch: 1, iteration: 26\n",
      "epoch: 1, iteration: 28\n",
      "epoch: 1, iteration: 30\n",
      "epoch: 1, iteration: 32\n",
      "epoch: 1, iteration: 34\n",
      "epoch: 1, iteration: 36\n",
      "epoch: 1, iteration: 38\n",
      "epoch: 1, iteration: 40\n",
      "epoch: 1, iteration: 42\n",
      "epoch: 1, iteration: 44\n",
      "epoch: 1, iteration: 46\n",
      "epoch: 1, iteration: 48\n",
      "epoch: 1, iteration: 50\n",
      "epoch: 1, iteration: 52\n",
      "epoch: 1, iteration: 54\n",
      "epoch: 1, iteration: 56\n",
      "epoch: 1, iteration: 58\n",
      "epoch: 1, iteration: 60\n",
      "epoch: 1, iteration: 62\n",
      "epoch: 1, iteration: 64\n",
      "epoch: 1, iteration: 66\n",
      "epoch: 1, iteration: 68\n",
      "epoch: 1, iteration: 70\n",
      "epoch: 1, iteration: 72\n",
      "epoch: 1, iteration: 74\n",
      "epoch: 1, iteration: 76\n",
      "epoch: 1, iteration: 78\n",
      "epoch: 1, iteration: 80\n",
      "epoch: 1, iteration: 82\n",
      "epoch: 1, iteration: 84\n",
      "epoch: 1, iteration: 86\n",
      "epoch: 1, iteration: 88\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    for  i, (inputs, labels) in enumerate(dataloader):\n",
    "        #Perform Forward, backward and update opration here using inputs\n",
    "        if (i+1)%2==0:\n",
    "            print(f'epoch: {epoch}, iteration: {i+1}')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda_venv",
   "language": "python",
   "name": ".conda_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
