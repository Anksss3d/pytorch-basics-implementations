{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n"
     ]
    }
   ],
   "source": [
    "#prepare Data\n",
    "\n",
    "#Load DataSet\n",
    "bc_dataset = datasets.load_breast_cancer()\n",
    "X, y = bc_dataset.data, bc_dataset.target\n",
    "\n",
    "n_samples, n_features = X.shape \n",
    "\n",
    "print(n_samples, n_features)\n",
    "\n",
    "#Split the Dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1234)\n",
    "\n",
    "\n",
    "#Scale the data\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)\n",
    "\n",
    "\n",
    "#Convert to the torch Tensors\n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0], 1)\n",
    "y_test = y_test.view(y_test.shape[0], 1)\n",
    "\n",
    "input_size, output_size = n_features, 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Define Model\n",
    "class LogisticRegression(nn.Module):\n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        y_predicted = torch.sigmoid(self.linear(x))\n",
    "        return y_predicted\n",
    "    \n",
    "\n",
    "\n",
    "model = LogisticRegression(input_size, output_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define Loss and Optimizer\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5: loss=0.7525\n",
      "epoch 10: loss=0.6534\n",
      "epoch 15: loss=0.5794\n",
      "epoch 20: loss=0.5230\n",
      "epoch 25: loss=0.4788\n",
      "epoch 30: loss=0.4432\n",
      "epoch 35: loss=0.4140\n",
      "epoch 40: loss=0.3895\n",
      "epoch 45: loss=0.3687\n",
      "epoch 50: loss=0.3508\n",
      "epoch 55: loss=0.3352\n",
      "epoch 60: loss=0.3215\n",
      "epoch 65: loss=0.3092\n",
      "epoch 70: loss=0.2983\n",
      "epoch 75: loss=0.2884\n",
      "epoch 80: loss=0.2795\n",
      "epoch 85: loss=0.2713\n",
      "epoch 90: loss=0.2638\n",
      "epoch 95: loss=0.2569\n",
      "epoch 100: loss=0.2506\n",
      "epoch 105: loss=0.2446\n",
      "epoch 110: loss=0.2391\n",
      "epoch 115: loss=0.2340\n",
      "epoch 120: loss=0.2291\n",
      "epoch 125: loss=0.2246\n",
      "epoch 130: loss=0.2203\n",
      "epoch 135: loss=0.2163\n",
      "epoch 140: loss=0.2125\n",
      "epoch 145: loss=0.2088\n",
      "epoch 150: loss=0.2054\n",
      "epoch 155: loss=0.2021\n",
      "epoch 160: loss=0.1990\n",
      "epoch 165: loss=0.1960\n",
      "epoch 170: loss=0.1932\n",
      "epoch 175: loss=0.1905\n",
      "epoch 180: loss=0.1879\n",
      "epoch 185: loss=0.1854\n",
      "epoch 190: loss=0.1830\n",
      "epoch 195: loss=0.1807\n",
      "epoch 200: loss=0.1785\n",
      "epoch 205: loss=0.1763\n",
      "epoch 210: loss=0.1743\n",
      "epoch 215: loss=0.1723\n",
      "epoch 220: loss=0.1704\n",
      "epoch 225: loss=0.1685\n",
      "epoch 230: loss=0.1667\n",
      "epoch 235: loss=0.1650\n",
      "epoch 240: loss=0.1633\n",
      "epoch 245: loss=0.1617\n",
      "epoch 250: loss=0.1601\n",
      "epoch 255: loss=0.1586\n",
      "epoch 260: loss=0.1571\n",
      "epoch 265: loss=0.1557\n",
      "epoch 270: loss=0.1543\n",
      "epoch 275: loss=0.1530\n",
      "epoch 280: loss=0.1516\n",
      "epoch 285: loss=0.1504\n",
      "epoch 290: loss=0.1491\n",
      "epoch 295: loss=0.1479\n",
      "epoch 300: loss=0.1467\n",
      "epoch 305: loss=0.1456\n",
      "epoch 310: loss=0.1445\n",
      "epoch 315: loss=0.1434\n",
      "epoch 320: loss=0.1423\n",
      "epoch 325: loss=0.1413\n",
      "epoch 330: loss=0.1402\n",
      "epoch 335: loss=0.1393\n",
      "epoch 340: loss=0.1383\n",
      "epoch 345: loss=0.1373\n",
      "epoch 350: loss=0.1364\n",
      "epoch 355: loss=0.1355\n",
      "epoch 360: loss=0.1346\n",
      "epoch 365: loss=0.1338\n",
      "epoch 370: loss=0.1329\n",
      "epoch 375: loss=0.1321\n",
      "epoch 380: loss=0.1313\n",
      "epoch 385: loss=0.1305\n",
      "epoch 390: loss=0.1297\n",
      "epoch 395: loss=0.1290\n",
      "epoch 400: loss=0.1282\n",
      "epoch 405: loss=0.1275\n",
      "epoch 410: loss=0.1268\n",
      "epoch 415: loss=0.1261\n",
      "epoch 420: loss=0.1254\n",
      "epoch 425: loss=0.1247\n",
      "epoch 430: loss=0.1240\n",
      "epoch 435: loss=0.1234\n",
      "epoch 440: loss=0.1228\n",
      "epoch 445: loss=0.1221\n",
      "epoch 450: loss=0.1215\n",
      "epoch 455: loss=0.1209\n",
      "epoch 460: loss=0.1203\n",
      "epoch 465: loss=0.1197\n",
      "epoch 470: loss=0.1192\n",
      "epoch 475: loss=0.1186\n",
      "epoch 480: loss=0.1181\n",
      "epoch 485: loss=0.1175\n",
      "epoch 490: loss=0.1170\n",
      "epoch 495: loss=0.1164\n",
      "epoch 500: loss=0.1159\n",
      "epoch 505: loss=0.1154\n",
      "epoch 510: loss=0.1149\n",
      "epoch 515: loss=0.1144\n",
      "epoch 520: loss=0.1139\n",
      "epoch 525: loss=0.1135\n",
      "epoch 530: loss=0.1130\n",
      "epoch 535: loss=0.1125\n",
      "epoch 540: loss=0.1121\n",
      "epoch 545: loss=0.1116\n",
      "epoch 550: loss=0.1112\n",
      "epoch 555: loss=0.1107\n",
      "epoch 560: loss=0.1103\n",
      "epoch 565: loss=0.1099\n",
      "epoch 570: loss=0.1095\n",
      "epoch 575: loss=0.1091\n",
      "epoch 580: loss=0.1087\n",
      "epoch 585: loss=0.1083\n",
      "epoch 590: loss=0.1079\n",
      "epoch 595: loss=0.1075\n",
      "epoch 600: loss=0.1071\n",
      "epoch 605: loss=0.1067\n",
      "epoch 610: loss=0.1063\n",
      "epoch 615: loss=0.1060\n",
      "epoch 620: loss=0.1056\n",
      "epoch 625: loss=0.1053\n",
      "epoch 630: loss=0.1049\n",
      "epoch 635: loss=0.1045\n",
      "epoch 640: loss=0.1042\n",
      "epoch 645: loss=0.1039\n",
      "epoch 650: loss=0.1035\n",
      "epoch 655: loss=0.1032\n",
      "epoch 660: loss=0.1029\n",
      "epoch 665: loss=0.1025\n",
      "epoch 670: loss=0.1022\n",
      "epoch 675: loss=0.1019\n",
      "epoch 680: loss=0.1016\n",
      "epoch 685: loss=0.1013\n",
      "epoch 690: loss=0.1010\n",
      "epoch 695: loss=0.1007\n",
      "epoch 700: loss=0.1004\n",
      "epoch 705: loss=0.1001\n",
      "epoch 710: loss=0.0998\n",
      "epoch 715: loss=0.0995\n",
      "epoch 720: loss=0.0992\n",
      "epoch 725: loss=0.0989\n",
      "epoch 730: loss=0.0987\n",
      "epoch 735: loss=0.0984\n",
      "epoch 740: loss=0.0981\n",
      "epoch 745: loss=0.0978\n",
      "epoch 750: loss=0.0976\n",
      "epoch 755: loss=0.0973\n",
      "epoch 760: loss=0.0970\n",
      "epoch 765: loss=0.0968\n",
      "epoch 770: loss=0.0965\n",
      "epoch 775: loss=0.0963\n",
      "epoch 780: loss=0.0960\n",
      "epoch 785: loss=0.0958\n",
      "epoch 790: loss=0.0955\n",
      "epoch 795: loss=0.0953\n",
      "epoch 800: loss=0.0950\n",
      "epoch 805: loss=0.0948\n",
      "epoch 810: loss=0.0946\n",
      "epoch 815: loss=0.0943\n",
      "epoch 820: loss=0.0941\n",
      "epoch 825: loss=0.0939\n",
      "epoch 830: loss=0.0937\n",
      "epoch 835: loss=0.0934\n",
      "epoch 840: loss=0.0932\n",
      "epoch 845: loss=0.0930\n",
      "epoch 850: loss=0.0928\n",
      "epoch 855: loss=0.0925\n",
      "epoch 860: loss=0.0923\n",
      "epoch 865: loss=0.0921\n",
      "epoch 870: loss=0.0919\n",
      "epoch 875: loss=0.0917\n",
      "epoch 880: loss=0.0915\n",
      "epoch 885: loss=0.0913\n",
      "epoch 890: loss=0.0911\n",
      "epoch 895: loss=0.0909\n",
      "epoch 900: loss=0.0907\n",
      "epoch 905: loss=0.0905\n",
      "epoch 910: loss=0.0903\n",
      "epoch 915: loss=0.0901\n",
      "epoch 920: loss=0.0899\n",
      "epoch 925: loss=0.0897\n",
      "epoch 930: loss=0.0895\n",
      "epoch 935: loss=0.0893\n",
      "epoch 940: loss=0.0892\n",
      "epoch 945: loss=0.0890\n",
      "epoch 950: loss=0.0888\n",
      "epoch 955: loss=0.0886\n",
      "epoch 960: loss=0.0884\n",
      "epoch 965: loss=0.0883\n",
      "epoch 970: loss=0.0881\n",
      "epoch 975: loss=0.0879\n",
      "epoch 980: loss=0.0877\n",
      "epoch 985: loss=0.0876\n",
      "epoch 990: loss=0.0874\n",
      "epoch 995: loss=0.0872\n",
      "epoch 1000: loss=0.0870\n"
     ]
    }
   ],
   "source": [
    "#Training The Model\n",
    "epochs = 1000\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    #forward pass\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "    #backward pass\n",
    "    loss.backward()\n",
    "    \n",
    "    \n",
    "    #update\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    #print details\n",
    "    if (epoch+1)%5 == 0:\n",
    "        print(f'epoch {epoch+1}: loss={loss.item():.4f}')\n",
    "        \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy:  0.9474\n"
     ]
    }
   ],
   "source": [
    "#Test The Model\n",
    "\n",
    "y_predicted = model(X_test).detach()\n",
    "y_predicted_cls = y_predicted.round()\n",
    "\n",
    "# print(y_predicted_cls, y_test)\n",
    "\n",
    "acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0])\n",
    "\n",
    "print(f'accuracy: {acc: .4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda_venv",
   "language": "python",
   "name": ".conda_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
